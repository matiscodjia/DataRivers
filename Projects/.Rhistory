plot(modridge)
text(rep(450,10), coef(modridge)[length(seq(0,500,1)),-1], colnames(data1)[2:11])
modridge = lm.ridge(y ~ .,data1,lambda=seq(0,500,by=0.1))
plot(modridge)
text(rep(450,10), coef(modridge)[length(seq(0,500,0.1)),-1], colnames(data1)[2:11])
install.packages("glmnet")
library("glmnet")
source("~/Local/Code/R/Projects/tp2.R", echo=TRUE)
ggplot(data1,aes(x = x.3,y=y))+geom_smooth()
vecteur <- rnorm(3000,0,3)
modridge = lm.ridge(y ~ .,data1,lambda=seq(0,500,by=0.1))
plot(modridge)
text(rep(450,10), coef(modridge)[length(seq(0,500,0.1)),-1], colnames(data1)[2:11])
library(qpcR)
AICc(mod13)
install.packages("MASS")
library("MASS")
stepAIC(modall,trace = TRUE)
modridge = lm.ridge(y ~ .,data1,lambda=seq(0,500,by=0.1))
plot(modridge)
text(rep(450,10), coef(modridge)[length(seq(0,500,0.1)),-1], colnames(data1)[2:11])
x = as.matrix(data1[,-1])
fit = glmnet(x,y)
library("glmnet")
y = as.matrix(data1$y)
x = as.matrix(data1[,-1])
fit = glmnet(x,y)
plot(fit,xvar ="lambda", label = TRUE)
summary(fit)
cvfit = cv.glmnet(x,y)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
# Supposons que vous avez déjà effectué la validation croisée
cvfit <- cv.glmnet(x, y)
# Obtenir le lambda optimal
lambda_min <- cvfit$lambda.min
# Coefficients pour le lambda optimal
coefficients_min <- coef(cvfit, s = "lambda.min")
# Plot des données réelles
plot(x, y, pch = 19, col = "blue", xlab = "X", ylab = "Y")
# Plot des valeurs estimées
x_values <- seq(min(x), max(x), length.out = 100)
y_values <- predict(cvfit, newx = matrix(x_values), s = "lambda.min")
lines(x_values, y_values, col = "red", lwd = 2)
# Plot de la valeur à estimer
abline(v = x_value_to_estimate, col = "green", lty = 2)
# Ajouter une légende
legend("topright", legend = c("Données réelles", "Valeurs estimées", "Valeur à estimer"),
col = c("blue", "red", "green"), lwd = c(1, 2, 1), pch = c(19, NA, NA))
# Plot des données réelles
plot(x, y, pch = 19, col = "blue", xlab = "X", ylab = "Y")
# Coefficients pour le lambda optimal
coefficients_min <- coef(cvfit, s = "lambda.min")
# Plot des données réelles
plot(x, y, pch = 19, col = "blue", xlab = "X", ylab = "Y")
# Supposons que vous avez déjà effectué la validation croisée
cvfit <- cv.glmnet(x, y)
lambda_min <- cvfit$lambda.min
coefficients_min <- coef(cvfit, s = "lambda.min")
y = as.matrix(data1$y)
x = as.matrix(data1[,-1])
fit = glmnet(x,y)
plot(fit,xvar ="lambda", label = TRUE)
# Supposons que vous avez déjà effectué la validation croisée
cvfit <- cv.glmnet(x, y)
lambda_min <- cvfit$lambda.min
coefficients_min <- coef(cvfit, s = "lambda.min")
coefficients_min
data1$y_estimate = 3*data1$x.3 + 2*data1$x.5
ggplot(data1, aes(x = x.3)) +
geom_smooth(aes(y = y1, color = "Variable réelle")) +
geom_smooth(aes(y = y2, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur") +
scale_color_manual(values = c("y" = "blue", "y_estimate" = "red")) +
theme_minimal()
ggplot(data1, aes(x = x.3)) +
geom_smooth(aes(y = y1, color = "Variable réelle")) +
geom_smooth(aes(y = y2, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur") +
scale_color_manual(values = c("y" = "blue", "y_estimate" = "red")) +
theme_minimal()
library("tidyverse")
ggplot(data1, aes(x = x.3)) +
geom_smooth(aes(y = y1, color = "Variable réelle")) +
geom_smooth(aes(y = y2, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur") +
scale_color_manual(values = c("y" = "blue", "y_estimate" = "red")) +
theme_minimal()
ggplot(data1, aes(x = x.3)) +
geom_smooth(aes(y = y, color = "Variable réelle")) +
geom_smooth(aes(y = y_estimate, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur") +
scale_color_manual(values = c("y" = "blue", "y_estimate" = "red")) +
theme_minimal()
ggplot(data1, aes(x = x.3)) +
geom_smooth(aes(y = y, color = "Variable réelle")) +
geom_smooth(aes(y = y_estimate, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur") +
scale_color_manual(values = c("y" = "blue", "y_estimate" = "red")) +
theme_minimal()
ggplot(data1, aes(x = x.3)) +
geom_smooth(aes(y = y, color = "Variable réelle")) +
geom_smooth(aes(y = y_estimate, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur")
datap = read.table("prostate-data.txt", header = T)
setwd("/Users/mtis/Local/Code/R/Data/ISTIC")
datap = read.table("prostate-data.txt", header = T)
datap
y = as.matrix(datap$lpsa)
x = as.matrix(datap[,-1])
fit = glmnet(x,y)
plot(fit,xvar ="lambda", label = TRUE)
y = as.matrix(datap$lpsa)
x = as.matrix(datap[,-2])
fit = glmnet(x,y)
plot(fit,xvar ="lambda", label = TRUE)
x = as.matrix(datap[,c('lcavol','lweight','age','lbph','lcp','gleason','pgg45')])
fit = glmnet(x,y)
plot(fit,xvar ="lambda", label = TRUE)
cvfit <- cv.glmnet(x, y)
lambda_min <- cvfit$lambda.min
coefficients_min <- coef(cvfit, s = "lambda.min")
coefficients_min
datap$y_estimate = 0.6*datap$lcavol + 0.7*data1$lweight
datap$y_estimate = 0.6*datap$lcavol + 0.7*datap$lweight
ggplot(datap, aes(x = lcavol)) +
geom_smooth(aes(y = lspa, color = "Variable réelle")) +
geom_smooth(aes(y = y_estimate, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur")
ggplot(datap, aes(x = lcavol)) +
geom_smooth(aes(y = lpsa, color = "Variable réelle")) +
geom_smooth(aes(y = y_estimate, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur")
y = as.matrix(data1$y)
y = as.matrix(data1$y)
y = as.matrix(data1$y)
y = as.matrix(data1$y)
x = as.matrix(data1[,-1])
fit = glmnet(x,y)
plot(fit,xvar ="lambda", label = TRUE)
# Supposons que vous avez déjà effectué la validation croisée
cvfit <- cv.glmnet(x, y)
lambda_min <- cvfit$lambda.min
coefficients_min <- coef(cvfit, s = "lambda.min")
coefficients_min
data1$y_estimate = 3*data1$x.3 + 2*data1$x.5
library("tidyverse")
ggplot(data1, aes(x = x.3)) +
geom_smooth(aes(y = y, color = "Variable réelle")) +
geom_smooth(aes(y = y_estimate, color = "Variable estimée")) +
labs(title = "Variables en fonction de x", x = "x", y = "Valeur")
setwd("~/Local/Code/R/Projects")
setwd("/Users/mtis/Local/Code/R/Data/ISTIC")
data = read.csv('breast_cancer.csv')
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
class(data$diagnosis)
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
data
col = colnames(data)
length(col)
dim(data)
selco = data[2:31]
selco
selco = data[3:31]
selco
data = sample(selco,5)
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data1 = sample(selco,5)
data1
data1 = data1 + data$diagnosis
data1 = data1$diagnosis = data$diagnosis
data1
data1$diagnosis = data$diagnosis
data1 = sample(selco,5)
data1$diagnosis = data$diagnosis
data1
data1$id = data$id
data1
data[data$id = 842302,]
[data$id = 842302,]
data[data$id == 842302,]
data2 = sample(selco,5)
data2$diagnosis = data$diagnosis
data2$id = data$id
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test]
dat2.train = data2[-indices_test]
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binommial(link = 'logit'), data = dat2.train)
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
coefficients(mod)[0]
coefficients(mod)[1]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
data2$id = data$id
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
dat2.train
coefficients(mod)[1] + coefficients(mod)[2]* 0.049040 + coefficients(mod)[3]*122.80 + coefficients(mod)[4]*0.27760 + coefficients(mod)[5]*0.053730 + coefficients(mod)[6]* 17.33
coefficients(mod)[1] + coefficients(mod)[2]* 0.049040 + coefficients(mod)[3]*122.80 + coefficients(mod)[4]*0.27760 + coefficients(mod)[5]*0.053730 + coefficients(mod)[6]* 17.33
dat2.test
coefficients(mod)[1] + coefficients(mod)[2]* 0.014430 + coefficients(mod)[3]*87.44 + coefficients(mod)[4]*0.11380 + coefficients(mod)[5]*.015090 + coefficients(mod)[6]* 25.16
predict(newdata = data2.test)
predict(newdata = dat2.test)
predict(mod,newdata = dat2.test)
exp(1.028558)/(1+exp(1.028558))
plogis(predict(mod,newdata = dat2.test)) > 0.5
table(predict(mod,dat2.test$diagnosis),dat2.test$diagnosis)
predictions = plogis(predict(mod,newdata = dat2.test)) > 0.5
table(predictions,dat2.test)
table(predictions)
table(dat2.test$diagnosis == 'M')
table(dat2.test$diagnosis == 'B')
table(predictions)
table(dat2.test$diagnosis == 'B')
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
dat2.test
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
coefficients(mod)[1] + coefficients(mod)[2]* 0.014430 + coefficients(mod)[3]*87.44 + coefficients(mod)[4]*0.11380 + coefficients(mod)[5]*.015090 + coefficients(mod)[6]* 25.16
predict(mod,newdata = dat2.test)
exp(1.028558)/(1+exp(1.028558))
predictions = plogis(predict(mod,newdata = dat2.test)) > 0.5
table(predictions)
table(dat2.test$diagnosis == 'B')
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
`data2
data2$diagnosis = data$diagnosis
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
dat2.test
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
coefficients(mod)[1] + coefficients(mod)[2]* 0.014430 + coefficients(mod)[3]*87.44 + coefficients(mod)[4]*0.11380 + coefficients(mod)[5]*.015090 + coefficients(mod)[6]* 25.16
predict(mod,newdata = dat2.test)
exp(1.028558)/(1+exp(1.028558))
predictions = plogis(predict(mod,newdata = dat2.test)) > 0.5
table(predictions)
table(dat2.test$diagnosis == 'B')
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
dat2.test
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
coefficients(mod)[1] + coefficients(mod)[2]* 0.014430 + coefficients(mod)[3]*87.44 + coefficients(mod)[4]*0.11380 + coefficients(mod)[5]*.015090 + coefficients(mod)[6]* 25.16
predict(mod,newdata = dat2.test)
exp(1.028558)/(1+exp(1.028558))
predictions = plogis(predict(mod,newdata = dat2.test)) > 0.5
table(predictions)
table(dat2.test$diagnosis == 'B')
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
dat2.test
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
coefficients(mod)[1] + coefficients(mod)[2]* 0.014430 + coefficients(mod)[3]*87.44 + coefficients(mod)[4]*0.11380 + coefficients(mod)[5]*.015090 + coefficients(mod)[6]* 25.16
predict(mod,newdata = dat2.test)
exp(1.028558)/(1+exp(1.028558))
predictions = plogis(predict(mod,newdata = dat2.test)) > 0.5
table(predictions)
table(dat2.test$diagnosis == 'B')
data = read.csv('breast_cancer.csv')
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "M"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
dat2.test
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
coefficients(mod)[1] + coefficients(mod)[2]* 0.014430 + coefficients(mod)[3]*87.44 + coefficients(mod)[4]*0.11380 + coefficients(mod)[5]*.015090 + coefficients(mod)[6]* 25.16
predict(mod,newdata = dat2.test)
exp(1.028558)/(1+exp(1.028558))
predictions = plogis(predict(mod,newdata = dat2.test)) > 0.5
table(predictions)
table(dat2.test$diagnosis == 'B')
cm = table(predictions)
confusion_matrix <- confusionMatrix(predictions, dat2.test)
library(caret)
install.packages('caret')
library(caret)
confusion_matrix <- confusionMatrix(predictions, dat2.test)
library(caret)
confusion_matrix <- confusionMatrix(predictions, dat2.test)
confusion_matrix <- confusionMatrix(predictions, dat2.test$diagnosis =="B")
library(caret)
confusion_matrix <- confusionMatrix(predictions, dat2.test$diagnosis =="B")
confusion_matrix <- confusionMatrix(predictions$diagnosis, dat2.test$diagnosis)
actual = dat2.test$diagnosis == "B"
confusion_matrix <- confusionMatrix(predictions,actual)
actual
predictions
predictions
table(predictions,dat2.test$diagnosis)
table[1]
table[1][2]
table[1,2]
table[1,2]
table[1;2]
table[1:2]
table[1]
34/34+6
34/(34+6)
acc = 34/(34+6)
sensitivity(table)
sensitivity(table,FALSE)
sensitivity(predictions,actual)
acc = 34/(34+5)
sensitivity = 34/(34+6)
specificity = 55/(55+5)
fpr = 1 - specificity
tpr = 1 - sensitivity
fpr
tpr
install.packages('ROCR')
predict_prob = plogis(predict(mod,newdata = dat2.test))
ROCRpred = prediction(predic_prob, dat2.test$diagnosis)
ROCRperf = performance(ROCRpred, measure = "tpr", x.measure = "fpr")
library('ROCR')
predict_prob = plogis(predict(mod,newdata = dat2.test))
ROCRpred = prediction(predic_prob, dat2.test$diagnosis)
ROCRperf = performance(ROCRpred, measure = "tpr", x.measure = "fpr")
ROCRpred = prediction(predic_prob, dat2.test$diagnosis)
predict_prob = plogis(predict(mod,newdata = dat2.test))
ROCRpred = prediction(predict_prob, dat2.test$diagnosis)
ROCRperf = performance(ROCRpred, measure = "tpr", x.measure = "fpr")
plot(ROCRperf,colorize ="TRUE",text.adj = c(-0.2,1.7),print.cutoffs.at = seq(0,1,0.1))
tpr
data = read.csv('breast_cancer.csv')
data$diagnosis = factor(data$diagnosis)
data = within(data,diagnosis <- relevel(diagnosis,ref = "B"))
data$diagnosis
col = colnames(data)
dim(data)
length(col)
selco = data[3:31]
data2 = sample(selco,5)
data2
data2$diagnosis = data$diagnosis
data2
indices_test <- sample(1:nrow(data2), size = 100, replace = F)
dat2.test = data2[indices_test,]
dat2.train = data2[-indices_test,]
dat2.test
library('glmnet')
mod = glm(diagnosis ~ .,
control = glm.control(epsilon = 1e-8,maxit = 40, trace = TRUE),
family=binomial(link = 'logit'), data = dat2.train)
coefficients(mod)
coefficients(mod)[1] + coefficients(mod)[2]* 0.014430 + coefficients(mod)[3]*87.44 + coefficients(mod)[4]*0.11380 + coefficients(mod)[5]*.015090 + coefficients(mod)[6]* 25.16
predict(mod,newdata = dat2.test)
exp(1.028558)/(1+exp(1.028558))
threshold = 0.5
predictions = plogis(predict(mod,newdata = dat2.test)) > threshold
actual = dat2.test$diagnosis == "B"
actual
predictions
table = table(predictions,dat2.test$diagnosis)
acc = 34/(34+5)
table
table[1]
TN = table[1]
table[2]
tpr
install.packages('ROCR')
library('ROCR')
predict_prob = plogis(predict(mod,newdata = dat2.test))
ROCRpred = prediction(predict_prob, dat2.test$diagnosis)
ROCRperf = performance(ROCRpred, measure = "tpr", x.measure = "fpr")
plot(ROCRperf,colorize ="TRUE",text.adj = c(-0.2,1.7),print.cutoffs.at = seq(0,1,0.1))
acc = 34/(34+5)
install.packages('ROCR')
install.packages("ROCR")
library('ROCR')
predict_prob = plogis(predict(mod,newdata = dat2.test))
ROCRpred = prediction(predict_prob, dat2.test$diagnosis)
ROCRperf = performance(ROCRpred, measure = "tpr", x.measure = "fpr")
